{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01808146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the cleanrl ppo implementation for discrete action spaces\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "def make_env(env_id, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        if capture_video and idx == 0:\n",
    "            env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        return env\n",
    "\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1e6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, envs):\n",
    "        super().__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 1), std=1.0),\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n",
    "        )\n",
    "    def get_value(self, x):\n",
    "        return self.critic(x)\n",
    "    \n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits = self.actor(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bca3440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPS:  11182\n",
      "SPS:  11198\n",
      "SPS:  11341\n",
      "SPS:  11341\n",
      "SPS:  11345\n",
      "SPS:  11356\n",
      "SPS:  11392\n",
      "SPS:  11381\n",
      "SPS:  11397\n",
      "SPS:  11415\n",
      "SPS:  11441\n",
      "SPS:  11421\n",
      "SPS:  11418\n",
      "SPS:  11416\n",
      "SPS:  11429\n",
      "SPS:  11425\n",
      "SPS:  11370\n",
      "SPS:  11360\n",
      "SPS:  11349\n",
      "SPS:  11306\n",
      "SPS:  11295\n",
      "SPS:  11304\n",
      "SPS:  11303\n",
      "SPS:  11278\n",
      "SPS:  11265\n",
      "SPS:  11255\n",
      "SPS:  11253\n",
      "SPS:  11260\n",
      "SPS:  11263\n",
      "SPS:  11256\n",
      "SPS:  11255\n",
      "SPS:  11249\n",
      "SPS:  11246\n",
      "SPS:  11252\n",
      "SPS:  11259\n",
      "SPS:  11271\n",
      "SPS:  11283\n",
      "SPS:  11295\n",
      "SPS:  11308\n",
      "SPS:  11317\n",
      "SPS:  11332\n",
      "SPS:  11344\n",
      "SPS:  11352\n",
      "SPS:  11359\n",
      "SPS:  11365\n",
      "SPS:  11372\n",
      "SPS:  11381\n",
      "SPS:  11388\n",
      "SPS:  11396\n",
      "SPS:  11403\n",
      "SPS:  11410\n",
      "SPS:  11419\n",
      "SPS:  11426\n",
      "SPS:  11429\n",
      "SPS:  11435\n",
      "SPS:  11441\n",
      "SPS:  11450\n",
      "SPS:  11454\n",
      "SPS:  11453\n",
      "SPS:  11456\n",
      "SPS:  11456\n",
      "SPS:  11466\n",
      "SPS:  11471\n",
      "SPS:  11475\n",
      "SPS:  11480\n",
      "SPS:  11485\n",
      "SPS:  11488\n",
      "SPS:  11488\n",
      "SPS:  11497\n",
      "SPS:  11507\n",
      "SPS:  11509\n",
      "SPS:  11511\n",
      "SPS:  11513\n",
      "SPS:  11513\n",
      "SPS:  11514\n",
      "SPS:  11515\n",
      "SPS:  11515\n",
      "SPS:  11516\n",
      "SPS:  11518\n",
      "SPS:  11523\n",
      "SPS:  11526\n",
      "SPS:  11521\n",
      "SPS:  11526\n",
      "SPS:  11528\n",
      "SPS:  11531\n",
      "SPS:  11533\n",
      "SPS:  11534\n",
      "SPS:  11532\n",
      "SPS:  11533\n",
      "SPS:  11537\n",
      "SPS:  11538\n",
      "SPS:  11538\n",
      "SPS:  11539\n",
      "SPS:  11541\n",
      "SPS:  11542\n",
      "SPS:  11543\n",
      "SPS:  11547\n",
      "SPS:  11547\n",
      "SPS:  11548\n",
      "SPS:  11550\n",
      "SPS:  11549\n",
      "SPS:  11548\n",
      "SPS:  11548\n",
      "SPS:  11548\n",
      "SPS:  11548\n",
      "SPS:  11548\n",
      "SPS:  11548\n",
      "SPS:  11549\n",
      "SPS:  11549\n",
      "SPS:  11549\n",
      "SPS:  11549\n",
      "SPS:  11550\n",
      "SPS:  11550\n",
      "SPS:  11551\n",
      "SPS:  11553\n",
      "SPS:  11553\n",
      "SPS:  11552\n",
      "SPS:  11554\n",
      "SPS:  11559\n",
      "SPS:  11559\n",
      "SPS:  11559\n",
      "SPS:  11559\n",
      "SPS:  11559\n",
      "SPS:  11561\n",
      "SPS:  11564\n",
      "SPS:  11565\n",
      "SPS:  11565\n",
      "SPS:  11567\n",
      "SPS:  11568\n",
      "SPS:  11570\n",
      "SPS:  11570\n",
      "SPS:  11571\n",
      "SPS:  11573\n",
      "SPS:  11574\n",
      "SPS:  11574\n",
      "SPS:  11574\n",
      "SPS:  11575\n",
      "SPS:  11578\n",
      "SPS:  11579\n",
      "SPS:  11579\n",
      "SPS:  11579\n",
      "SPS:  11579\n",
      "SPS:  11579\n",
      "SPS:  11578\n",
      "SPS:  11580\n",
      "SPS:  11581\n",
      "SPS:  11581\n",
      "SPS:  11581\n",
      "SPS:  11582\n",
      "SPS:  11583\n",
      "SPS:  11586\n",
      "SPS:  11586\n",
      "SPS:  11586\n",
      "SPS:  11587\n",
      "SPS:  11589\n",
      "SPS:  11589\n",
      "SPS:  11590\n",
      "SPS:  11592\n",
      "SPS:  11593\n",
      "SPS:  11594\n",
      "SPS:  11596\n",
      "SPS:  11596\n",
      "SPS:  11596\n",
      "SPS:  11597\n",
      "SPS:  11596\n",
      "SPS:  11597\n",
      "SPS:  11597\n",
      "SPS:  11598\n",
      "SPS:  11598\n",
      "SPS:  11598\n",
      "SPS:  11600\n",
      "SPS:  11601\n",
      "SPS:  11601\n",
      "SPS:  11601\n",
      "SPS:  11600\n",
      "SPS:  11600\n",
      "SPS:  11600\n",
      "SPS:  11600\n",
      "SPS:  11600\n",
      "SPS:  11600\n",
      "SPS:  11599\n",
      "SPS:  11599\n",
      "SPS:  11599\n",
      "SPS:  11599\n",
      "SPS:  11598\n",
      "SPS:  11598\n",
      "SPS:  11598\n",
      "SPS:  11598\n",
      "SPS:  11597\n",
      "SPS:  11597\n",
      "SPS:  11598\n",
      "SPS:  11598\n",
      "SPS:  11597\n",
      "SPS:  11596\n",
      "SPS:  11596\n",
      "SPS:  11596\n",
      "SPS:  11596\n",
      "SPS:  11595\n",
      "SPS:  11596\n",
      "SPS:  11595\n",
      "SPS:  11595\n",
      "SPS:  11595\n",
      "SPS:  11594\n",
      "SPS:  11594\n",
      "SPS:  11593\n",
      "SPS:  11592\n",
      "SPS:  11590\n",
      "SPS:  11590\n",
      "SPS:  11591\n",
      "SPS:  11590\n",
      "SPS:  11590\n",
      "SPS:  11590\n",
      "SPS:  11589\n",
      "SPS:  11590\n",
      "SPS:  11589\n",
      "SPS:  11589\n",
      "SPS:  11589\n",
      "SPS:  11589\n",
      "SPS:  11587\n",
      "SPS:  11587\n",
      "SPS:  11587\n",
      "SPS:  11586\n",
      "SPS:  11585\n",
      "SPS:  11586\n",
      "SPS:  11586\n",
      "SPS:  11586\n",
      "SPS:  11586\n",
      "SPS:  11586\n",
      "SPS:  11585\n",
      "SPS:  11584\n",
      "SPS:  11583\n",
      "SPS:  11584\n",
      "SPS:  11584\n",
      "SPS:  11584\n",
      "SPS:  11584\n",
      "SPS:  11584\n",
      "SPS:  11584\n",
      "SPS:  11583\n",
      "SPS:  11582\n",
      "SPS:  11582\n",
      "SPS:  11582\n",
      "SPS:  11582\n",
      "SPS:  11583\n",
      "SPS:  11582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "num_envs = 16\n",
    "n_steps = 256\n",
    "n_minibatches = 10\n",
    "total_timesteps = 1_000_000\n",
    "capture_video = False\n",
    "env_id = \"LunarLander-v3\"\n",
    "learning_rate = 2.5e-4\n",
    "anneal_lr = True\n",
    "seed=1\n",
    "gamma = 0.99\n",
    "gae_lambda = 0.95\n",
    "clip_coef = 0.2\n",
    "update_epochs = 10\n",
    "norm_adv = True\n",
    "clip_vloss = True\n",
    "ent_coef = 0.01\n",
    "vf_coef = 0.5\n",
    "max_grad_norm = 0.5\n",
    "target_kl = None\n",
    "\n",
    "\n",
    "batch_size = num_envs * n_steps\n",
    "minibatch_size = batch_size // n_minibatches\n",
    "num_iterations = total_timesteps // batch_size\n",
    "\n",
    "\n",
    "run_name = f\"ppo_discrete_{num_envs}envs_{total_timesteps}timesteps\"\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# env setup\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(env_id, i, capture_video, run_name) for i in range(num_envs)]\n",
    ")\n",
    "\n",
    "agent = Agent(envs).to(device)\n",
    "optimizer = optim.Adam(agent.parameters(), lr=learning_rate, eps=1e-5)\n",
    "\n",
    "# Algo logic: Storage setup\n",
    "obs = torch.zeros((n_steps, num_envs) + envs.single_observation_space.shape).to(device)\n",
    "actions = torch.zeros((n_steps, num_envs) + envs.single_action_space.shape).to(device)\n",
    "logprobs = torch.zeros((n_steps, num_envs)).to(device)\n",
    "rewards = torch.zeros((n_steps, num_envs)).to(device)\n",
    "dones = torch.zeros((n_steps, num_envs)).to(device)\n",
    "values = torch.zeros((n_steps, num_envs)).to(device)\n",
    "\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "next_obs, _ = envs.reset(seed=seed)\n",
    "next_obs = torch.Tensor(next_obs).to(device)\n",
    "next_done = torch.zeros(num_envs).to(device)\n",
    "\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    # annealing the rate if instructed\n",
    "    if anneal_lr:\n",
    "        frac = 1.0 - (iteration - 1.0) / num_iterations\n",
    "        lrnow = frac * learning_rate\n",
    "        optimizer.param_groups[0][\"lr\"] = lrnow\n",
    "\n",
    "    for step in range(0, n_steps):\n",
    "        global_step += num_envs\n",
    "        obs[step] = next_obs\n",
    "        dones[step] = next_done\n",
    "\n",
    "        # ALGO LOGIC: action logic\n",
    "        with torch.no_grad():\n",
    "            action, logprob, _, value = agent.get_action_and_value(next_obs)\n",
    "            values[step] = value.flatten()\n",
    "        actions[step] = action\n",
    "        logprobs[step] = logprob\n",
    "\n",
    "        next_obs, reward, terminations, truncations, infos = envs.step(action.cpu().numpy())\n",
    "        next_done = np.logical_or(terminations, truncations)\n",
    "        rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
    "        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(next_done).to(device)\n",
    "\n",
    "        if \"final_info\" in infos:\n",
    "            for info in infos[\"final_info\"]:\n",
    "                if info and \"episode\" in info:\n",
    "                    print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
    "\n",
    "    \n",
    "    # bootstrap value if not done\n",
    "    with torch.no_grad():\n",
    "        next_value = agent.get_value(next_obs).reshape(1, -1)\n",
    "        advantages = torch.zeros_like(rewards).to(device)\n",
    "        lastgaelam = 0\n",
    "        for t in reversed(range(n_steps)):\n",
    "            if t == n_steps - 1:\n",
    "                nextnonterminal = 1.0 - next_done\n",
    "                nextvalues = next_value\n",
    "            else:\n",
    "                nextnonterminal = 1.0 - dones[t + 1]\n",
    "                nextvalues = values[t + 1]\n",
    "            delta = rewards[t] + gamma * nextvalues * nextnonterminal - values[t]\n",
    "            advantages[t] = lastgaelam = delta + gamma * gae_lambda * nextnonterminal * lastgaelam\n",
    "        returns = advantages + values\n",
    "\n",
    "    # flatten the batch\n",
    "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
    "    b_logprobs = logprobs.reshape(-1)\n",
    "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
    "    b_advantages = advantages.reshape(-1)\n",
    "    b_returns = returns.reshape(-1)\n",
    "    b_values = values.reshape(-1)\n",
    "\n",
    "    # Optimizing the policy and value network\n",
    "    b_inds = np.arange(batch_size)\n",
    "    clipfracs = []\n",
    "    for epoch in range(update_epochs):\n",
    "        np.random.shuffle(b_inds)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            mb_inds = b_inds[start:end]\n",
    "\n",
    "            _, newlogprob, entropy, newvalue = agent.get_action_and_value(\n",
    "                b_obs[mb_inds], b_actions.long()[mb_inds]\n",
    "            )\n",
    "            logratio = newlogprob - b_logprobs[mb_inds]\n",
    "            ratio = logratio.exp()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
    "                old_approx_kl = (-logratio).mean()\n",
    "                approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                clipfracs += [((ratio - 1.0).abs() > clip_coef).float().mean().item()]\n",
    "\n",
    "            mb_advantages = b_advantages[mb_inds]\n",
    "            if norm_adv:\n",
    "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 -clip_coef, 1 + clip_coef)\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "\n",
    "            # Value loss\n",
    "            newvalue = newvalue.view(-1)\n",
    "            if clip_vloss:\n",
    "                v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
    "                v_clipped = b_values[mb_inds] + torch.clamp(\n",
    "                    newvalue - b_values[mb_inds],\n",
    "                    -clip_coef,\n",
    "                    clip_coef,\n",
    "                )\n",
    "                v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
    "                v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
    "                v_loss = 0.5 * v_loss_max.mean()\n",
    "            else:\n",
    "                v_loss = 0.5 * ((b_returns[mb_inds] - newvalue) ** 2).mean()\n",
    "            \n",
    "            entropy_loss = entropy.mean()\n",
    "            loss = pg_loss + ent_coef * entropy_loss + v_loss * vf_coef\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "        \n",
    "        if target_kl is not None and approx_kl > target_kl:\n",
    "            break\n",
    "\n",
    "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
    "    var_y = np.var(y_true)\n",
    "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
    "\n",
    "    print(\"SPS: \", int(global_step / (time.time() - start_time)))\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d33dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run it over a test environment and render the results\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "test_env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    obs_tensor = torch.Tensor(obs).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        action, _, _, _ = agent.get_action_and_value(obs_tensor)\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action.cpu().numpy()[0])\n",
    "    done = terminated or truncated\n",
    "\n",
    "    frame = test_env.render()\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if done or truncated:\n",
    "        obs, _ = test_env.reset()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3d218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirtyRL (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
