{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bda43a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "env_name = \"LunarLander-v3\"\n",
    "env = gym.make(env_name, render_mode=\"human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e46f7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_envs = gym.make_vec(env_name, num_envs=4)\n",
    "state = vec_envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77fbfbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the environment in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Create environment with rgb_array for visualization (no video recording)\n",
    "env = gym.make(env_name, render_mode='rgb_array')\n",
    "print(\"Environment created:\", env)\n",
    "\n",
    "# Reset and get initial observation\n",
    "obs, info = env.reset()\n",
    "print(\"Observation space:\", obs.shape)\n",
    "print(\"Info:\", info)\n",
    "\n",
    "# Run a random episode and display it in real-time\n",
    "done = False\n",
    "start_time = time.time()\n",
    "\n",
    "# Create figure once\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "while time.time() - start_time < 10:  # Run for 10 seconds\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # Get frame and display it\n",
    "    frame = env.render()\n",
    "    \n",
    "    # Clear previous plot and show new frame\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Pendulum Environment - Reward: {reward:.2f}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Reset if episode ends\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "    \n",
    "    time.sleep(0.05)  # Small delay to see the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caf25b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d755c8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e923629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "from collections import deque\n",
    "from typing import List, Tuple\n",
    "\n",
    "def initialize_weights(layer: nn.Module):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            nn.init.zeros_(layer.bias)\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 128):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Softmax(dim=-1)  # For discrete action spaces\n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.apply(initialize_weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        action_probs = self.actor(x)\n",
    "        state_value = self.critic(x)\n",
    "        return action_probs, state_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74ee39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(rewards: List[float], values: List[float], next_value: float, gamma: float = 0.99, lam: float = 0.95) -> List[float]:\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * next_value - values[step]\n",
    "        gae = delta + gamma * lam * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "        next_value = values[step]\n",
    "    return returns\n",
    "\n",
    "def ppo_update(\n",
    "    actor_critic: ActorCritic,\n",
    "    optimizer: Adam,\n",
    "    states: torch.Tensor,\n",
    "    actions: torch.Tensor,\n",
    "    old_log_probs: torch.Tensor,\n",
    "    returns: torch.Tensor,\n",
    "    advantages: torch.Tensor,\n",
    "    clip_ratio: float = 0.2\n",
    "):\n",
    "    action_probs, state_values = actor_critic(states)\n",
    "    \n",
    "    # Calculate log probabilities\n",
    "    dist = Categorical(action_probs)\n",
    "    log_probs = dist.log_prob(actions)\n",
    "    \n",
    "    # Calculate ratios\n",
    "    ratios = torch.exp(log_probs - old_log_probs)\n",
    "    \n",
    "    # Calculate surrogate losses\n",
    "    surrogate1 = ratios * advantages\n",
    "    surrogate2 = torch.clamp(ratios, 1 - clip_ratio, 1 + clip_ratio) * advantages\n",
    "    \n",
    "    actor_loss = -torch.min(surrogate1, surrogate2).mean() - 0.01 * dist.entropy().mean()  # Add entropy bonus for exploration\n",
    "    critic_loss = nn.MSELoss()(state_values.squeeze(), returns)\n",
    "    \n",
    "    loss = actor_loss + critic_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c7b4642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.action_space.nvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce57c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 3e-4\n",
    "input_dim = vec_envs.observation_space.shape[1]\n",
    "output_dim = vec_envs.action_space.shape[0]  # For discrete action spaces\n",
    "hidden_dim = 128\n",
    "num_episodes = 10000\n",
    "max_frames = 30_000\n",
    "\n",
    "# Initialize actor-critic model and optimizer\n",
    "actor_critic = ActorCritic(input_dim, output_dim, hidden_dim)\n",
    "optimizer = Adam(actor_critic.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29daa644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48ab4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def plot_rewards(rewards: List[float], title: str = \"Training Rewards\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(rewards, label='Average Reward')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_env(env, actor_critic, num_episodes: int = 10, visualize: bool = True):\n",
    "    test_rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        truncated = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not (done or truncated):\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            action_probs, _ = actor_critic(state_tensor)\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample()\n",
    "            \n",
    "            next_state, reward, done, truncated, info = env.step(action.item())\n",
    "            episode_reward += reward\n",
    "            \n",
    "            if visualize:\n",
    "                frame = env.render()\n",
    "                plt.imshow(frame)\n",
    "                plt.axis('off')\n",
    "                plt.title(f'Test Episode - Reward: {reward:.2f}')\n",
    "                plt.show()\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        test_rewards.append(episode_reward)\n",
    "    avg_reward = np.mean(test_rewards)\n",
    "    print(f\"Average Test Reward over {num_episodes} episodes: {avg_reward:.2f}\")\n",
    "    return test_rewards\n",
    "\n",
    "def train_ppo(vec_envs, env, actor_critic, optimizer, num_episodes: int = 10000, max_frames: int = 30_000):\n",
    "    frame_idx = 0\n",
    "    test_rewards = []\n",
    "    episode_rewards = deque(maxlen=100)\n",
    "    \n",
    "    for episode in tqdm.tqdm(range(num_episodes)):\n",
    "        state, info = vec_envs.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        states, actions, rewards, values, log_probs = [], [], [], [], []\n",
    "        \n",
    "        next_state = state  # Initialize next_state to current state\n",
    "        \n",
    "        while frame_idx < max_frames:\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            action_probs, value = actor_critic(state_tensor)\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample()\n",
    "            \n",
    "            next_state, reward, done, truncated, info = vec_envs.step(action.cpu().numpy()[0])\n",
    "            log_prob = dist.log_prob(action)\n",
    "            \n",
    "            states.append(state_tensor)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            values.append(value)\n",
    "            log_probs.append(log_prob)\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            frame_idx += 1\n",
    "            \n",
    "        episode_rewards.append(episode_reward)\n",
    "        \n",
    "        # Only update if we have collected some data\n",
    "        if len(states) > 0:\n",
    "            # Compute GAE and returns\n",
    "            _, next_value = actor_critic(torch.FloatTensor(next_state).unsqueeze(0))\n",
    "            print(next_value)\n",
    "            next_value = next_value.squeeze()\n",
    "            returns = compute_gae(rewards, values, next_value)\n",
    "            \n",
    "            # Convert lists to tensors\n",
    "            states_tensor = torch.cat(states)\n",
    "            actions_tensor = torch.tensor(actions)\n",
    "            log_probs_tensor = torch.cat(log_probs)\n",
    "            returns_tensor = torch.tensor(returns).float()\n",
    "            \n",
    "            # Calculate advantages\n",
    "            values_tensor = torch.cat(values).squeeze()\n",
    "            advantages = returns_tensor - values_tensor\n",
    "            \n",
    "            # Update the model using PPO\n",
    "            ppo_update(actor_critic, optimizer, states_tensor, actions_tensor, log_probs_tensor, returns_tensor, advantages)\n",
    "\n",
    "        if episode % 1000 == 0:\n",
    "            test_reward = test_env(env, actor_critic, num_episodes=10, visualize=False)\n",
    "            test_rewards.append(np.mean(test_reward))\n",
    "            avg_reward = np.mean(episode_rewards) if episode_rewards else 0\n",
    "            print(f\"Episode {episode}, Average Reward: {avg_reward:.2f}, Frame Index: {frame_idx}, Test Reward: {np.mean(test_reward):.2f}\")    \n",
    "    return test_rewards\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a53ad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0545],\n",
      "         [-0.3460],\n",
      "         [ 0.0261],\n",
      "         [ 0.0156]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the PPO agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_rewards = \u001b[43mtrain_ppo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_critic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m plot_rewards(test_rewards, title=\u001b[33m\"\u001b[39m\u001b[33mPPO Training Rewards\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mtrain_ppo\u001b[39m\u001b[34m(vec_envs, env, actor_critic, optimizer, num_episodes, max_frames)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(next_value)\n\u001b[32m     84\u001b[39m next_value = next_value.squeeze()\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m returns = \u001b[43mcompute_gae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Convert lists to tensors\u001b[39;00m\n\u001b[32m     88\u001b[39m states_tensor = torch.cat(states)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcompute_gae\u001b[39m\u001b[34m(rewards, values, next_value, gamma, lam)\u001b[39m\n\u001b[32m      3\u001b[39m returns = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rewards))):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     delta = \u001b[43mrewards\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_value\u001b[49m - values[step]\n\u001b[32m      6\u001b[39m     gae = delta + gamma * lam * gae\n\u001b[32m      7\u001b[39m     returns.insert(\u001b[32m0\u001b[39m, gae + values[step])\n",
      "\u001b[31mTypeError\u001b[39m: Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations."
     ]
    }
   ],
   "source": [
    "# Train the PPO agent\n",
    "test_rewards = train_ppo(vec_envs, env, actor_critic, optimizer, num_episodes=10000, max_frames=max_frames)\n",
    "plot_rewards(test_rewards, title=\"PPO Training Rewards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a9c2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State tensor shape: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "state, info = vec_envs.reset()\n",
    "episode_reward = 0\n",
    "states, actions, rewards, values, log_probs = [], [], [], [], []\n",
    "\n",
    "next_state = state  # Initialize next_state to current state\n",
    "state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "print(\"State tensor shape:\", state_tensor.shape)\n",
    "action_probs, value = actor_critic(state_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1968af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1961, 0.3169, 0.2212, 0.2657],\n",
       "         [0.1790, 0.3054, 0.2469, 0.2687],\n",
       "         [0.1613, 0.3620, 0.2369, 0.2398],\n",
       "         [0.1775, 0.3610, 0.2214, 0.2402]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "216f9425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Categorical(probs: torch.Size([1, 4, 4])), tensor([[1, 2, 2, 2]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Categorical(action_probs)\n",
    "action = dist.sample()\n",
    "dist, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e648948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "705feaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ed99598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1760db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "325daf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0207015 ,  1.4376045 , -0.70805174,  0.36898848,  0.02823097,\n",
       "          0.22109969,  0.        ,  0.        ],\n",
       "        [ 0.0130722 ,  1.4391944 ,  0.4405354 ,  0.44750464, -0.01374587,\n",
       "         -0.09139954,  0.        ,  0.        ],\n",
       "        [ 0.01492996,  1.378388  ,  0.5005176 , -0.48031557, -0.02251425,\n",
       "         -0.17477141,  0.        ,  0.        ],\n",
       "        [-0.01559029,  1.4337385 , -0.7815169 ,  0.52460545,  0.01885197,\n",
       "          0.19445577,  0.        ,  0.        ]], dtype=float32),\n",
       " array([-1.49397397, -3.43256539,  1.92220309, -3.01464674]),\n",
       " array([False, False, False, False]),\n",
       " array([False, False, False, False]),\n",
       " {})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.step(action.cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35605f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirtyRL (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
