{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda43a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "env_name = \"LunarLander-v3\"\n",
    "env = gym.make(env_name, render_mode=\"human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46f7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_envs = gym.make_vec(env_name, num_envs=2)\n",
    "state = vec_envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fbfbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAF0CAYAAAC+FDqzAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAANo9JREFUeJzt3Xd4FOX+NvB7tmU3lRDSEwglAZEm/SChSBU8CNJBpQkcOOKLggIHFTgWmiiKCiqKCPijKYoCFjBCABUUkBYgQBKSQBrpyW62zftH3D0sQVJIskme+8O1F9nJ7Mx3Z8vceZ5nZiRZlmUQERGRsBTOLoCIiIici2GAiIhIcAwDREREgmMYICIiEhzDABERkeAYBoiIiATHMEBERCQ4hgEiIiLBMQwQEREJjmGAHPz888+QJAk///xzuR8bHx8PSZLw6aefVnpdtVGvXr3Qq1cvZ5dBdQjfU1RVGAac7NNPP4UkSfabVqtFREQEnn76aaSmpjq7vFpv8eLFDtv39ltKSoqzSxRGYWEhFi9eXKGgWRpbELXdFAoF6tevj4cffhi//PJLpa+vrrFarVixYgUaN24MrVaLNm3a4P/+7//K9NgDBw5g8uTJiIiIgKurK5o0aYKnnnoKN27cKDHvDz/8gClTpqBVq1ZQKpUICwur5GdCFaVydgFU7L///S8aN24Mg8GAw4cPY+3atdi7dy/Onj0LV1dXZ5dX661duxbu7u4lpterV6/K1vnDDz9U2bJro8LCQixZsgQAquyv27Fjx2LQoEGwWCy4dOkS3n//ffTu3RvHjx9H69atq2SddcHChQuxbNkyTJ06FZ06dcLXX3+NcePGQZIkjBkz5q6PnTdvHjIzMzFy5EiEh4fj6tWrePfdd/Htt9/i1KlTCAgIsM/7+eefY9u2bWjfvj2CgoKq+mlRecjkVBs2bJAByMePH3eY/txzz8kA5M8//7xa64mKipIByFFRUeV+bFxcnAxA3rBhQ6XXVVGLFi2SAcjp6enOLuWO9Hq9bLFYnF1GtUhPT5cByIsWLar0ZdveeytXrnSYvm/fPhmAPGPGjEpfZ1XIz8+/6+979uwp9+zZs1LXmZSUJKvVavnf//63fZrVapUjIyPlkJAQ2Ww23/XxBw8eLPEePnjwoAxAXrhwocP05ORk2Wg0yrIsy4MHD5YbNWpUOU+C7hm7CWqohx56CAAQFxdnn7Z582Z06NABOp0O9evXx5gxY5CYmOjwuF69eqFVq1Y4f/48evfuDVdXVwQHB2PFihUl1pGUlIShQ4fCzc0Nfn5+ePbZZ1FUVFRivrCwMEycOLHE9LL0X/7dPBMnTnRoIrQ1877xxht477330KRJE7i6uqJ///5ITEyELMt45ZVXEBISAp1Oh0cffRSZmZl3XXd52MZKbN++Ha+99hpCQkKg1WrRp08fXL582T7f008/DXd3dxQWFpZYxtixYxEQEACLxXLH525bx9atW/Hiiy8iODgYrq6uyM3NBQDs2LHD/vo2aNAAjz/+OJKTk0tsN3d3dyQnJ2Po0KFwd3eHr68v5s6da19vZW7Pffv2ITIyEm5ubvDw8MDgwYNx7ty5ctcUHx8PX19fAMCSJUvszfmLFy8ux6tUfpGRkQCAK1euOEzPzs7G7NmzERoaChcXFzRr1gzLly+H1Wq1z9O+fXs89thjDo9r3bo1JEnC6dOn7dO2bdsGSZIQExMDAEhISMDMmTPRvHlz6HQ6+Pj4YOTIkYiPj3dYlq2L8ODBg5g5cyb8/PwQEhJi//2HH36Ipk2bQqfToXPnzoiOjr7jc7x27RouXLhQ/o3zl6+//homkwkzZ860T5MkCTNmzEBSUlKp3Sw9evSAQqEoMa1+/fr2bWITFBQEtVpd4Vqp6rCboIayfXn5+PgAAF577TW89NJLGDVqFJ566imkp6djzZo16NGjB06ePOnQ3J2VlYWBAwfisccew6hRo7Bz507MmzcPrVu3xsMPPwwA0Ov16NOnD65du4ZnnnkGQUFB2LRpE3766adqf6632rJlC4xGI2bNmoXMzEysWLECo0aNwkMPPYSff/4Z8+bNw+XLl7FmzRrMnTsXn3zySZmWe6cdnUqlKtFNsGzZMigUCsydOxc5OTlYsWIFxo8fj99++w0AMHr0aLz33nvYs2cPRo4caX9cYWEhvvnmG0ycOBFKpfKutbzyyivQaDSYO3cuioqKoNFo8Omnn2LSpEno1KkTli5ditTUVLz99ts4cuRIidfXYrFgwIAB6NKlC9544w3s378fq1atQtOmTTFjxoxK256bNm3ChAkTMGDAACxfvhyFhYVYu3YtunfvjpMnTzqEudJq8vX1xdq1azFjxgwMGzbMvpNt06bNXbfVvbLtgL29ve3TCgsL0bNnTyQnJ2P69Olo2LAhjh49igULFuDGjRtYvXo1gOIgcWu/eWZmJs6dOweFQoHo6Gh77dHR0fD19cV9990HADh+/DiOHj2KMWPGICQkBPHx8Vi7di169eqF8+fPl+j2mzlzJnx9ffHyyy+joKAAAPDxxx9j+vTp6NatG2bPno2rV69iyJAhqF+/PkJDQx0e/+STT+LgwYOQK3g1+pMnT8LNzc1ev03nzp3tv+/evXu5lpmfn4/8/Hw0aNCgQjWREzi5ZUJ4tm6C/fv3y+np6XJiYqK8detW2cfHR9bpdHJSUpIcHx8vK5VK+bXXXnN47JkzZ2SVSuUwvWfPnjIA+bPPPrNPKyoqkgMCAuThw4fbp61evVoGIG/fvt0+raCgQG7WrFmJboJGjRrJEyZMKFH77U2Wd+om+LtmzQkTJjg0Edoe6+vrK2dnZ9unL1iwQAYgt23bVjaZTPbpY8eOlTUajWwwGEos+1a2boI73Zo3b26fz9Y9ct9998lFRUX26W+//bYMQD5z5owsy8XNp8HBwQ7bUpZlefv27TIA+dChQ3/73G3raNKkiVxYWGifbjQaZT8/P7lVq1ayXq+3T//2229lAPLLL7/ssN0AyP/9738d1v/AAw/IHTp0qLTtmZeXJ9erV0+eOnWqw3pSUlJkLy8vh+llrak6ugmWLFkip6enyykpKXJ0dLTcqVMnGYC8Y8cO+7yvvPKK7ObmJl+6dMlhGfPnz5eVSqV87do1WZZleceOHTIA+fz587Isy/Lu3btlFxcXeciQIfLo0aPtj2vTpo08bNgw+/1bX1ubX375pcTn0vbZ7969u0NTvO390K5dO4f34ocffigDKPF5sn3mK2rw4MFykyZNSkwvKCiQAcjz588v9zJfeeUVGYB84MCBu66X3QQ1B7sJaoi+ffvC19cXoaGhGDNmDNzd3bFr1y4EBwfjyy+/hNVqxahRo5CRkWG/BQQEIDw8HFFRUQ7Lcnd3x+OPP26/r9Fo0LlzZ1y9etU+be/evQgMDMSIESPs01xdXTFt2rSqf7J3MXLkSHh5ednvd+nSBQDw+OOPQ6VSOUw3Go0lmtH/zhdffIEff/zR4bZhw4YS802aNAkajcZ+39bMbNt2kiRh5MiR2Lt3L/Lz8+3zbdu2DcHBwWX6C2rChAnQ6XT2+7///jvS0tIwc+ZMaLVa+/TBgwejRYsW2LNnT4ll/Otf/3K4HxkZ6fD62lR0e/7444/Izs7G2LFjHd5zSqUSXbp0KfGeK09NVWnRokXw9fVFQEAAIiMjERMTg1WrVjm8z3fs2IHIyEh4e3s7PLe+ffvCYrHg0KFD9voB2O9HR0ejU6dO6Nevn73JPjs7G2fPnrXPC8DhtTWZTLh58yaaNWuGevXq4cSJEyVqnjp1qkNrku398K9//cvhvThx4kSH19Lm559/rnCrAFDcSuji4lJiuu29qNfry7W8Q4cOYcmSJfYWKKod2E1QQ7z33nuIiIiASqWCv78/mjdvbu+Hi42NhSzLCA8Pv+Njb++DCwkJgSRJDtO8vb0d+jkTEhLQrFmzEvM1b968Mp5OhTVs2NDhvu3L7/amUdv0rKysMi23R48eZWqyvH39tublW9czevRorF69Grt378a4ceOQn5+PvXv3Yvr06SW25500btzY4X5CQgKAO2/7Fi1a4PDhww7TtFqtvf/91jrvtC0quj1jY2MB4G+/zD09PStcU1lYLBakp6c7TKtfv77DzvFOpk2bhpEjR8JgMOCnn37CO++84zCWAih+bqdPny5Rr01aWhoAwN/fH+Hh4YiOjsb06dMRHR2N3r17o0ePHpg1axauXr2KmJgYWK1WhzCg1+uxdOlSbNiwAcnJyQ476pycnBLr+7v3w+2fd7VajSZNmtz1+d/N7YfRenl5QafTQafT3XGskMFgAOAYbkpz4cIFDBs2DK1atcL69esrXCtVP4aBGqJz587o2LHjHX9ntVohSRL27dt3x/7o2w+Z+7s+64r+9fB3OziLxVJq/7gkSXdc7+1f0DZ/t7zKfk5/pyzr6dq1K8LCwrB9+3aMGzcO33zzDfR6PUaPHl2mdZTny7U8NZZn3tKep20g3aZNmxwODbO5tVWhvDWVRWJiYomdZFRUVKkDVsPDw9G3b18AwCOPPAKlUon58+ejd+/e9s+X1WpFv3798MILL9xxGREREfafu3fvjgMHDkCv1+OPP/7Ayy+/jFatWqFevXqIjo5GTEwM3N3d8cADD9gfM2vWLGzYsAGzZ8/GP/7xD3h5edkP0bt1gKLNvb4fyiowMNDh/oYNGzBx4kQEBgYiKioKsiw7fNZt5wko6yGAiYmJ6N+/P7y8vLB37154eHhUXvFU5RgGaoGmTZtClmU0btzY4YvqXjRq1Ahnz54t8QVw8eLFEvN6e3sjOzu7xPSEhIRS/1Lx9va+Y1Ox7a+f2mrUqFF4++23kZubi23btiEsLAxdu3at0LIaNWoEoHjb3/6X+MWLF+2/r05NmzYFAPj5+dl3rveqLK0mNgEBAfjxxx8dprVt27bc61y4cCE++ugjvPjii/juu+8AFD+3/Pz8Mj2vyMhIbNiwAVu3boXFYkG3bt2gUCjQvXt3exjo1q2bQxjauXMnJkyYgFWrVtmnGQyGO36G7sT2esfGxjq8H0wmE+Li4iq0HQCU2J73338/AKBdu3ZYv349YmJi0LJlS/vvbYNm27VrV+qyb968if79+6OoqAgHDhwoETyo5uOYgVrgscceg1KpxJIlS0r8JSzLMm7evFnuZQ4aNAjXr1/Hzp077dMKCwvx4Ycflpi3adOm+PXXX2E0Gu3Tvv322xKHNd5J06ZNceHCBYcm3z///BNHjhwpd801yejRo1FUVISNGzfiu+++w6hRoyq8rI4dO8LPzw/r1q1zaK7dt28fYmJiMHjw4MoouVwGDBgAT09PvP766zCZTCV+f3sTflnYRtGXZaeo1WrRt29fh9utRwSUVb169TB9+nR8//33OHXqFIDiIPfLL7/g+++/LzF/dnY2zGaz/b6t+X/58uVo06aNvTslMjISBw4cwO+//+7QRQAUt5Lc/jlds2bN37aG3a5jx47w9fXFunXrHD5zn3766R23XVkPLbx9e9p22I8++ijUajXef/99+7yyLGPdunUIDg5Gt27d7NNv3LiBCxcuOLwnCgoKMGjQICQnJ2Pv3r1/251JNRtbBmqBpk2b4tVXX8WCBQsQHx+PoUOHwsPDA3Fxcdi1axemTZuGuXPnlmuZU6dOxbvvvosnn3wSf/zxBwIDA7Fp06Y7nu3wqaeews6dOzFw4ECMGjUKV65cwebNm+1/Pd7N5MmT8eabb2LAgAGYMmUK0tLSsG7dOtx///324+urw86dO+94BsJ+/frB39+/3Mtr3749mjVrhoULF6KoqKjMXQR3olarsXz5ckyaNAk9e/bE2LFj7YcWhoWF4dlnn63wsivK09MTa9euxRNPPIH27dtjzJgx8PX1xbVr17Bnzx48+OCDePfdd8u1TJ1Oh5YtW2Lbtm2IiIhA/fr10apVK7Rq1aqKnkWx//f//h9Wr16NZcuWYevWrXj++eexe/duPPLII5g4cSI6dOiAgoICnDlzBjt37kR8fLx9fEmzZs0QEBCAixcvYtasWfZl9ujRA/PmzQOAEmHgkUcewaZNm+Dl5YWWLVvil19+wf79++2HCZdGrVbj1VdfxfTp0/HQQw9h9OjRiIuLw4YNG+7YEnevhxaGhIRg9uzZWLlyJUwmEzp16oSvvvoK0dHR2LJli0Orx4IFC7Bx40bExcXZDy0dP348jh07hsmTJyMmJsbh3ALu7u4YOnSo/f7p06exe/duAMDly5eRk5ODV199FUBxy88///nPCj0HuncMA7XE/PnzERERgbfeest+StfQ0FD0798fQ4YMKffyXF1dceDAAcyaNQtr1qyBq6srxo8fj4cffhgDBw50mHfAgAFYtWoV3nzzTcyePRsdO3bEt99+izlz5pS6nvvuuw+fffYZXn75ZTz33HNo2bIlNm3ahM8//7xKzlH/d24//t4mKiqqQmEAKG4deO2119CsWTO0b9/+XsrDxIkT4erqimXLlmHevHlwc3PDsGHDsHz58io9ZfLdjBs3DkFBQVi2bBlWrlyJoqIiBAcHIzIyEpMmTarQMtevX49Zs2bh2WefhdFoxKJFi6o8DAQFBWHcuHHYtGkTrly5gqZNm+LgwYN4/fXXsWPHDnz22Wfw9PREREQElixZUmLEfmRkJHbs2OFwpEiHDh3g6uoKs9lsP0LD5u2334ZSqcSWLVtgMBjw4IMPYv/+/RgwYECZa542bRosFgtWrlyJ559/Hq1bt8bu3bvx0ksv3dvG+BvLli2Dt7c3PvjgA3z66acIDw/H5s2bMW7cuFIfa2tx+eSTT0qc96NRo0YOYeDEiRMlnoPt/oQJExgGnEiSK3sEFhEREdUqHDNAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhJcmc8zUJ5TiRIREVHNUJYzCLBlgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREKTJAlqlYpXZiWhMQwQkbAUkoTQgAB0a9sWwX5+DAQkLIYBIhKWRqNB46AgAEDTkBColUonV0TkHAwDRCQsk8mEpNRUAMC1GzdgtlicXBGRc0iyLMtlmpHNZ0RUBykVCrhoNDAYjbBarc4uh6jSlWU3zzBARERUh5VlN89uAiIiIsExDBAREQmOYYCIiEhwDANEVGd0CgrCmFatoOEhgkTlwjBARHVChI8P2gYEwMPFBaPuv9/Z5RDVKgwDRFQn5BuNyDMaIcsyknNznV0OUa3CQwuJqM4I8fSEj6srzqSmwlq2rzaiOo+HFhIRAKBvSAg+6d0bwW5uzi6lSiXl5uLPlBQGAaJyYssAUR3Xun59bHjoIbir1bhpMKD311/DyDPtEQmDLQNEBLMso9BsBgDkGo3g38xEdDu2DBAJ4MGAAPwzLAxv/fknUvV6Z5dDRNWI1yYgIiISHLsJiIiIqFQqZxdAVHdJkCTpr1Y1CZKkgEKhhJubD9zdG8DD3RceHn7w8PDF9RtnEROz39kFE5GgGAaI7pEkKaBUqqFUqqBQqP/6WQ0XFw+4uXrD3d0Xnu7+qOcZCjfX+jCbjJBkFbQqL3jqgqFWuSIt7TLUah1MJvbnE1H1YxggKiNJUkCl0kKj0UGj0UGtLv5fpdLCReMOndYbHm7+8PFqDE/3QMhWGbIVUCm00Km9Uc+tITRKtxLjbwoM6fD2aAR39wbIykp00rMjIpExDBCVgbd3CEJDH4AEJTQqV7hpG8DHswnqezWFSuECWGVIkgpqhQ6uLvWhUbnD1k1QGq3aC2EBDyIu6Qiys5PKNNiHiKgyMQwQlYG7WwN0vG8CvF2aQIICCkkJlVILlVILCYp7OtpGqdTAVdMA9TxDkKK6yK4CIqp2DANEpfDzbo5HIlcAkgx3F/8qOczWUxuIRkFdEZfwK8MAEVU7HlpIVArbAEGg6s614erig/qeYfDw8K/S9RAR3QnDAFEpZMiALEOS7q07oDQemmCEBj8AhYIfSyKqXvzWISqNXBwIqvosnPXdmiDQ936o1boqXQ8R0e0YBohKJQOQIVXxx0WpUMPdJQB+fuFVuh4iotsxDBCVQv7rn1QNffnB3h3RKLQjOG6AiKoTwwBRmciAVPUfF52qPup5hsLV1bvK10VEZMMwQFQKGTJkuXpaBgDA36M1ggLvr5Z1EREBDANEZVA9YwZsfN2bw9e3KVQq7R1+y+4DIqp8DANEZVB8NEHVf1wkSYJKqYOXewjc3Hxu/Q28vILQps0/4e7uW+V1EJFYeAZCotLItpaB6vmrXIICntogaF3ckQNAp6uHZk0jcX/4YMiyjLS0WOTnZ6C4xYKI6N4xDBCVonjMAKqtm0CSFHDTNoBOVw+hAZ3Qrt0QBHq3Q6D7A8gqiEd44164eTMBJlNhtdRDRHUfuwmISiHDCpO1ADKs1bI+CRJ0mvrQaHTo3HISIvwHwWDOBiChvnsTNA56EP7+EdVSCxGJgWGAqIyssqWa1iTBReUJlUqDw6fWwGqyQqXQIbcoEQAQ6NEe90X0g0rlUk31EFFdxzBA5ECCQqF0OPWwUtLARekFK6onDEiSBAWUUKvdcDP3KgoNWfBza4VM/WVYrEboNPUQ6t0FTZp0q5Z6iKjuYxggukV4k57o/uA0NG0aCT+/ZnB394UkKaFUqGGxFkGWq2fQniQpoHOpB7Vaiw93DYQCKrhp/JFTdA2yLCOkfhc0Du3KIwuIqFIwDBD95b7Gg/FQlxcQXL89OrZ4ApFdnka7dsMgAVApXGCVzVXaVSDLMixWI4rMeTBZCuDu2gAajRtkWcbF+B/grvGH3pQNk7UAEhSICHgYjRp2+OvyykREFccwQPSXfl0WwmjNQ1C9B9AiaDB83MKRnnYZuQUpOHf5G8iyBVbZdM/rse309aZs5BYl42ZhLFLyTyEp91dcz/sD6YXnUWBOh1KpgSxbAMj45tDzOHtpN1QKFxQY0wHI8NQGIzy0D+rVC7nnmohIbDy0kMhGlqE3ZULr3hEAUGBMQ2ZmAvRFWUi48RvCGv4DVtlcrkVaZTOKzHkosuSiyJyLIksujJY8WGUL1ApXqJWuUEkuKCoqQE7edWTnJiE7LxFZuYnIzI3/63wCgNFcgNhrUWgVMRQZhRfgrgmASqFFiE8nBPrfj5yc6zCbiyp9kxCRGBgGiP5itBRAISmhUmhhtZphkYuQm5cGAFBKLpBhgVU2/zVuoPhKhvjrugUyrDBa8mAw56LInIMiSy4MpiwYLYVQK1yhUbpDo3CHJGtgyrMgMzseN3OuIj37MjJz4mAy6yHLVlhlK2Sr5a/uCMfxCVeSDuKPs5sR3qwHcooS4aMLRz3XRmgb8Riup5xBZmZCtW8zIqobGAaIAPh4NUGRNReumgaQJAkGcx5ycq/Dai1uCVAqXCDLFhSaMmC05MNk1cNkKYTJWgCjOR+FxkzACiighiSroJDVMBaZkJOXgazceNzMiUNmThzy9WkVrtEqm5GZmwA3VQBSCk/CyyUUaqUOPm7haNY4EifzUmEyGSprkxCRQBgGiAD07bwQSo0SruoGAACDORtpNy/Zw0BWbgKyc6+jUJsFk1EPk9EAs7kIZqMRJpMBen0O8gpTkVuQgtyCG8gruAGL9d7HF9zu5MX/Q4uwgfD1DUdqwRn4u7WGLFkRHtYbF2L3w2RKqfR1ElHdxzBA9JcCUzp8Xe8DAOhNWcjMjofVWnz0QHLaSRw5bkQ9j1AUFeVDX5RtvxlNBajO6wT8dnY9HntoDTJMl3Aj/wRyc1MRGx+FIkN+tdVARHULwwARALNVD7WsglrpBqtshdlqQH5BBmT5f6cgTsk4h5SMc06sstjV5Ghs2jMOw/q9iePnN+JyfDTyC1KrpCWCiMTAMEDCU6t0MMmF8FQ1hAQFzFY98gtTYTLpnV3a30rNPI/1O4fCYjX9dfghEVHFMQyQ8Lq2noqQwAfsLf0mqx7pWbEoKipwbmGlMFs4WJCIKgdPOkQEQG/Ogk5dHwBgNOcjMye+RrcMEBFVJoYBEp7ZWgSLtQgapZv9foHhJsxmo5MrIyKqHuwmIOHpTZnQmzJxLecwXDV+KNCnwVhUiOo8QoCIyJkYBkh4f8Z8gaTrJ9GkYST8fcOhN2dCb8h2dllERNVGkst4TdZbr+9OREREtUNZdvMcM0BERCQ4hgEiJ9Iplfh68GD8u3VrZ5dCRALjmAEiJ/p15Ei09vFB7+Bg3DQYsDU21tklEZGA2DJA5ERGa/Hpjq2yDEvZhu8QEVU6DiAkciKtUonP+vXD/sREfHjO+dc9IKK6pyy7eYYBIiKiOoxHExAREVGpGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEFUib40GzTw8oJYkZ5dCRFRmDANElaSeRoPHGjbEvyIi0C8oCIwDRFRbMAwQVZIGLi64z8sLANDL359hgIhqDYYBokqSUFCAqJQUWGUZH8XGwursgoiIykiSZVku04zsAyUqlQRAIUmwlO1jRURU5cqym2fLAFElkgEGASKqdRgGiIiIBMcwQEREJDiGASIiIsExDBAREQmOYYCIiEhwDANERESCYxggIiISHMMAERGR4BgGiIiIBMcwQEREJDiGASIiIsExDBAREQmOYYCIiEhwDANERESCYxggIiISHMMAERGR4BgGiIiIBMcwQEREJDiGASIiIsExDBAREQmOYYCIiEhwDANERESCYxggIiISHMMAERGR4BgGiIiIBMcwQEREJDiGASIiIsExDBAREQmOYYCIiEhwDANERESCYxggIiISHMMAERGR4BgGiIiIBMcwQEREJDiGASIiIsExDBAREQmOYYCIiEhwDANERESCYxggIiISnDBhQJIk9O7dGy+99BJ8fX2dXQ4REVGNIcmyLJdpRkmq6lqqVMeOHfHVV1/B29sbiYmJuHbtGtavX4/t27c7uzQiIqIqU5bdfJ0PAwqFAg888AAOHz4MrVZrn261WmE2m5GWloZvvvkGa9aswfXr15GTk+PEaomIiCqX8GFAo9HgoYcewrZt2+Dp6XnXeWVZxk8//YSlS5ciLy8PMTExyMvLq6ZKiYiIqobQYUCr1WLo0KFYsWIFQkNDy/w4q9WK69ev48svv8SFCxdw/Phx/P7771VYKRERUdURNgxoNBqMGDECr7/+Oho1alTh5RQWFuLSpUs4efIkDh8+jK+++gqZmZmVWCkREVHVEjIMKBQKDB8+HGvXroWPj0+lLNNisSAvLw9ZWVnYt28fnnnmGciyDKvVWinLJyIiqirChQEXFxeMGDECGzZsgFqtrpJ1WK1WGI1GxMTEYOnSpfjll1+Ql5fHgYdERFQjCRUGPD09MX78eCxduhReXl7Vtt60tDTs27cP27ZtQ1JSEq5cuYLCwsJqWz8REdHdCBMGvLy8MHnyZLzwwgsICAhwSg0GgwFnzpzBb7/9hl9//RVbt26FxWJxSi1EREQ2QoQBrVaLWbNmYc6cOfD393d2OQCKWwt+//13XLlyBZ999hmPRiAiIqep82FAqVRi3rx5WLBgAdzd3Z1djgNZlmEymZCbm4vY2Fjs2LEDa9euhclkYosBERFVmzodBjw9PfHcc89h4cKFUKlUzi7nrmybWK/X46OPPsK6detQUFCA5ORkHpFARERVqs6GAT8/P8yePRtPP/00PDw8nF1OuVksFpw+fRrvvvsukpOTce7cOSQlJTm7LCIiqoPqZBho0KAB5s2bhylTpsDb29vZ5dwTWZaRnp6OX3/9Fb/99huOHz+OqKgomM1mZ5dGRER1RJ0LAzqdDitXrsQTTzxR6rUGahu9Xo+UlBTExcVh69at+Oijj5xdEhER1QF1KgxoNBp8+OGHGDt2LDQajVNrqUqyLEOv1yMrKwtHjx7Ff/7zHyQnJ8NkMrHFgIiIyq3OhAE/Pz+sWrUKY8eOhVKpdFod1enWlyU2NhYbN27E7t27kZGRgbS0NA48JCKiMqkTYaBhw4ZYsmQJRo8eDZ1O55QaaoqbN2/i8OHD+PHHH3Ho0CGcOXPG2SUREVENV+vDQEBAAFatWoWhQ4fC1dW12tdfU8myjN9++w0//PADtmzZgkuXLjm7JCIiqqFqdRjQarXYtWsXevfuDRcXl2pdd21hMBgQFxeHL774AsuXL0d+fr6zSyIiohqm1oYBNzc37N+/H507d4ZCoai29dZWRqMRBQUFePXVV7F+/XoUFBTwLIdERASgloaBRo0aYePGjYiMjGQQqIC4uDisWLECBw4cwJUrVzjQkIhIcLUuDISHh2PNmjXo27evMEcNVJVjx45h69at+PHHH3H27Flnl0NERE5Sq8JAo0aN8Nlnn6F79+5sEagkVqsVx44dw/79+/HJJ58gLi7O2SUREVE1qzVhwMfHB0ePHkVERESVrUNker0eycnJ2LJlC15//XUYjUZnl0RERNWkxocBSZLQuHFjREVFITQ01OlnOazrzGYz8vLysHjxYmzZsgU5OTk8q+E9+s9/gEGDAFkGCgqAbduA3buLfyfLQFFR8XSqeoMHAwsWFG93kwk4fBh4++3//d5kAnJznVcfkbPU6DCgVCrRvn17rF+/Hm3atKnUZVPpYmJisHr1ahw6dAgXL14s05uFSnr5ZWDIEMdptk1pNAJHjgA7d/5venY2EBtbrSUKY8iQ4tfjVrbXwmIBLl8G3nnnf9P1eoDDaUgENTYMKJVK/OMf/8Abb7yBLl26VNpyqfx+/fVXfPHFF/juu+840LAC7hQGbmf7hFmtQHw8sG9f8TRZBm7eBPbsqfIyhXCnMHA722shy0BmZnFLjtVafD8/v/i1KCqq+lqJqlONDQPdunXD2rVr2SJQQ5hMJpw6dQrff/891q1bh+TkZGeXVGuUJQzc7tYdUl4e8Pvvxfet1uJw8PbbxU3aVD5lCQO3u/W1MBiKXwuTqfh+Tg7w6afAjRuVXipRtaqRYaBz58744osvEBISUinLo8qj1+uRlpaG9evXY9myZbBYLOw+KEVFwsDtbt3EZjNw4QIwadK9LVNEFQkDt7v1tbBYgLQ0YOxYjvug2q0s3+PVdgyfWq1Gv379sGvXLgQHB1fXaqkcdDodGjVqhMWLF+PGjRuYMWMG/P39oVKpnF1anWLrIpDl4nEF168X35KSgFOngH//29kViuPW18JsBlJT//danDsHPPssgwCJoVq+5V1cXDBw4EAsX74cQUFB1bFKugdKpRINGjTAe++9h2nTpuH9999HdHQ0YmJinF1arXRrU/TNm8D588U/W63FOx3boDaqere+FoWFwB9//C8MZGYWvxbc+ZOIqjwMqFQqDBkyBIsWLULz5s2renVUydq2bYsPPvgAR48exe7du7F7926GglLYdjhmMxATU3yIG1C8809MBA4ccF5torl18OaNG8A33/xv55+dDXz1lWPXAJGoqjwMjBgxAkuXLkVYWFhVr4qqULdu3dChQweMGjUKe/bswTvvvIOMjAxnl1Uj2HYmen3xkQI//1x832otbnaOj3dWZeKxvRYmE3DyJLBly/92/rm5xa0yRFRSlQ0gVCgUGDt2LFavXo0GDRpUqDiqmQwGA7KysrB69WqsXr0aZrNZ2AsiffjhG/j8849x/nwMrNbiJma93tlViWnChNHw8VFj8+bN9qMD8vKcXRWR8zltAKFOp8PkyZPx1ltvwcfHpypWQU6k1WoRGBiIZcuWIT4+HtOmTUNoaKiQF5dSqeojK0uDtDQgI4NBwJkUClcUFLghLQ1IT2cQICqPSg8Dbm5uePLJJ/HSSy/B19eXpxiuwyRJQmBgINauXYsvv/wSU6dORcuWLZ1dFhERlVOljhlQq9V46qmnMGfOHISGhlbmoqmG69ixIzp06IAjR45g37592LlzJy5duuTssoiIqAwqNQzMnTsXzz33HMcICEqSJHTv3h0dOnTA6NGjsWvXLrz55pvI5dVhiIhqtErpJlCpVHj55ZexYMECBgGCTqdDmzZtMH/+fFy+fBmzZ8+Gq6srFIpqO8cVERGVwz1/O3t4eGDhwoWYM2cO3N3dK6MmqiNcXFzg6+uLN998E+fOncPkyZMRFhbGUEBEVMPc07eyp6cn5syZg2eeeQaenp4cLEh3JEkSwsLC8NFHH2Hr1q2YMWMGBxoSEdUgFR4zoFKpsGjRIkyZMgVeXl6VWRPVYV26dEGnTp1w9OhRfPLJJ9iwYYOzSyIiEl6FWwbWrl2LGTNmMAhQuSkUCnTv3h0rV67E0aNH0bZtW2eXREQktHKHAa1Wi08++QRPPPEEtFptVdREgvDx8UHXrl1x5MgRXLx4Ed7e3tDpdM4ui4hIOOUKA/Xr18dbb72F8ePHw8XFhWME6J5JkgQ3NzdEREQgLS0NH3/8MTp37gxXV1dnl0ZEJIwyhwFPT0+8/vrrmDJlCjQaTVXWRIJSqVQYO3YsDhw4gJdeegmjRo1ydklEREIo8wDCjRs3YsiQITwsjKqcu7s75s2bh4yMDPTr1w9ffPEFvvvuO2eXRURUZ5V5zz506FAGAao2kiTB19cXkyZNwscff4zdu3cjKCjI2WUREdVJ3LtTjaZUKhEUFITBgwfjypUr2LFjB/z9/Tl4lYioElXqtQmIqopCoYBWq8WIESPQp08ffPDBB/jyyy9x6tQpmEwmZ5dHRH9Rq9UIDw9HYGAgioqKSr2ZzWZnl0xgGKBayNvbG/Pnz8eYMWOwadMmREVFISoqytllEQlNq9WiXbt26NevH/75z3/igQceQF5eHnJzc5Gbm2v/+fZpeXl5yM/PR35+vsPPt08zGo3Ofop1GsMA1VphYWF48cUXMWbMGOzfvx8ffPAB/vzzT2eXRSQUlUqFrl27Yty4cYiMjESLFi2gUhXvWry9veHt7X3Xx1ssFhgMBuj1ehgMhhI/2+7n5+cjOzsbmZmZyMzMRFZWlsP/tp8NBkN1PO06h2GAajVJkhAeHo6wsDA8+uij+PrrrzF//nzk5eVBlmVnl0dUZykUCnTs2BFz5sxBz5494e3tXaHDzpVKJdzc3ODm5nbX+axWKywWC8xmM8xms/3n2//Py8tDRkYGUlNTkZaWZr+lp6cjNTUV6enpSEtLg16vBwD798St3xcifncwDFCdoFarERQUhOnTp2PixIlYvnw53nvvPWRkZDi7NKI6Q5Ik1KtXD23btsUzzzyDAQMGQKvVVsuRZgqFAgqFAmq1+q7z3W3nfuv/+fn5SEtLcwgIttut07Kzs5Gbm4vCwsIqemY1A8MA1SkKhQI6nQ6LFy9G9+7dsWbNGhw6dAjZ2dnOLo2oVmvYsCHat2+P8ePHY8CAAfDw8HB2SXdkOzNuaWfItXVhNG/e/K7znTp1Cnv37sWhQ4cQFxeHa9eu1cmuCIYBqrP69u2LPn36YMOGDbhw4QJWrlzp7JKIahVJktC4cWMMGjQI/fv3R58+fYQ7VXi7du3Qtm1bzJo1C3/88QdOnDiB48eP49ixY7h69aqzy6s0DANUp0mShEmTJqGoqAg9e/bEjh07sHHjRmeXRVTjhYSEYMqUKRg8eDBatGhRY1sCqoMkSfDw8ECvXr3Qo0cPpKWlISEhAWfOnMHevXtx4MAB5ObmOrvMe8IwQHWeJEnQarUYNGgQevTogeeffx4jR47E5cuXeY4ColsolUqEhobiqaeewoQJE+Dj48Mrid5GoVAgICAA/v7+aN++PUaMGIGbN2/i22+/xeeff46TJ0/CYrHAarU6u9RyYRggYdjSfcuWLXH27FmcOnUK48ePR2pqKrKyspxdHpHTeHh4ICwsDOPGjcOTTz6JwMBAAKX3u4tMkiSo1WrUq1cPXl5eeOaZZ/Dvf/8bFy5cwLZt27Bv3z4kJycjKysLRUVFzi63VAwDJBxJkiBJEtq3b48TJ05g+/bt2LlzJw4cOGA/3IhIBD4+Pmjbti0GDx6M0aNHIzg42Nkl1Uq20KRSqdCqVSu0atUKL7zwAo4ePYoDBw7gxIkTiI2NRXJyMiwWi5OrvTOGARKaTqfDhAkTMGTIEOzYsQPR0dHYvHmzs8siqlI6nQ6PPvooHn74YfTq1QshISG8EF0l8/DwwIABA9C3b19cv34dp0+fxsmTJ3H06FEcP368xh32zDBAhOLDjKZOnYqhQ4di+PDheOedd3iKY6pzdDodRowYgWnTpqFZs2bw8/NjCKhitnEYoaGh6Nu3L1JTU5GQkIAjR47gq6++wokTJ2rE2CWGAaK/SJIEPz8/DBkyBH369MHRo0cxZcoUpKen87zoVGsplUp4enrikUcewZw5c9CsWTO4urpyPIATuLi4oGHDhggNDUWXLl0wc+ZMxMbGYuvWrdi1axeSk5NhNBqdMviQYYDoNgqFAh4eHujfvz8SEhKwefNmvPHGG0hISEBeXp6zyyMqE61Wi8DAQPTp0wczZ85Eu3btAHBQYE0gSRI0Gg00Gg3at2+P9u3bY/HixYiOjsbOnTtx7NgxpKSkICsrq9qu6sgwQPQ3JEmCUqnEhAkT8PDDD2Pz5s3Yt28foqKiauwgICIXFxe0bdsWvXv3xvDhw9GhQwd2BdRgtnDm5uaGgQMHYuDAgUhMTMShQ4dw5MgRnD59GjExMcjMzKzSOhgGiMrAz88Pzz33HIYNG4YffvgB27Zt45gCqnF69OiB4cOHo0ePHmjRogW0Wq2zS6IKCA0Nxfjx4zF8+HBcvXoV58+fx/Hjx3Hw4EH8+eefVXI6ZEkW8fJMRPfAarUiMTERBw8exNatW/Hzzz/zkMQaoEGDBpAkCenp6c4updp17doVs2fPRufOnREcHFyhqwdSzZaXl4e0tDRcuXIFe/bswZdffomkpKQyPbYsu3mGAaIKsl2HnV0GNUdOTg6uXbuG+Ph4+y0hIQFnz56FwWCwXwbXdoY428+17WtQkiS4urri/vvvx4svvog+ffrAxcUFCoWCYwLqOKvVCrPZDKPRiIMHD2Lz5s346aefkJeXB4PBcMf3MsMAERGKvwwLCwuRnJyMpKQkJCcnIzk5GYmJiUhKSkJ6ejoMBgMMBgP0ej30ej0MBgPy8vJq1GllVSoV/P390a5dO0yePBnDhg3jzp+QkpKCvXv34uuvv0ZsbCxu3LjhcKVWhgEiojIwGAzIzMxEeno60tPTkZGRgYyMDFy7dg2FhYXIzs5GTk6Ow/9ZWVnIz8+vthrDw8PRq1cvPPLII+jdu7fQFw6iO5NlGX/++SeOHj2KY8eO4fTp0zh79myZDo1mGCAiuguz2Yz8/Hzk5eU53HJzc5GdnY2MjAykpqYiJSUFaWlpSE1NxZUrV1BYWFgp64+IiMDIkSPRv39/tG7dGt7e3pWyXKrbcnJycPnyZcTGxmLMmDGlzs8wQERUQVarFSaTCUVFRTAajfZbYWEhjEYjkpKSkJiYiMTERFy7ds0+nsE28OtuX79BQUF4+umn8eijj6JRo0Y8URBVKYYBIqIqIMvy396KioqQkpLiMNgxISEBCQkJuHbtGp5++mlMmTIFnp6eHBRI1YJhgIiISHA8LRUREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCY5hgIiISHAMA0RERIJjGCAiIhIcwwAREZHgGAaIiIgExzBAREQkOIYBIiIiwTEMEBERCe7/A2o9wIPcAIeyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the environment in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Create environment with rgb_array for visualization (no video recording)\n",
    "env = gym.make(env_name, render_mode='rgb_array')\n",
    "print(\"Environment created:\", env)\n",
    "\n",
    "# Reset and get initial observation\n",
    "obs, info = env.reset()\n",
    "print(\"Observation space:\", obs.shape)\n",
    "print(\"Info:\", info)\n",
    "\n",
    "# Run a random episode and display it in real-time\n",
    "done = False\n",
    "start_time = time.time()\n",
    "\n",
    "# Create figure once\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "while time.time() - start_time < 10:  # Run for 10 seconds\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # Get frame and display it\n",
    "    frame = env.render()\n",
    "    \n",
    "    # Clear previous plot and show new frame\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Pendulum Environment - Reward: {reward:.2f}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Reset if episode ends\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "    \n",
    "    time.sleep(0.05)  # Small delay to see the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf25b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample() # Sample a random action, the output is a np.int64 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d755c8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e923629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "from collections import deque\n",
    "from typing import List, Tuple\n",
    "\n",
    "def initialize_weights(layer: nn.Module):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            nn.init.zeros_(layer.bias)\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 128):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Softmax(dim=-1)  # For discrete action spaces\n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.apply(initialize_weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        action_probs = self.actor(x)\n",
    "        state_value = self.critic(x)\n",
    "        return action_probs, state_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ee39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import Tensor\n",
    "def compute_gae(rewards: List[np.ndarray], values: List[Tensor], next_value: Tensor, gamma: float = 0.99, lam: float = 0.95) -> List[Tensor]:\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * next_value - values[step]\n",
    "        gae = delta + gamma * lam * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "        next_value = values[step]\n",
    "    return returns\n",
    "\n",
    "def ppo_update(\n",
    "    actor_critic: ActorCritic,\n",
    "    optimizer: Adam,\n",
    "    states: torch.Tensor,\n",
    "    actions: torch.Tensor,\n",
    "    old_log_probs: torch.Tensor,\n",
    "    returns: torch.Tensor,\n",
    "    advantages: torch.Tensor,\n",
    "    clip_ratio: float = 0.2\n",
    "):\n",
    "    action_probs, state_values = actor_critic(states)\n",
    "    \n",
    "    # Calculate log probabilities\n",
    "    dist = Categorical(action_probs)\n",
    "    log_probs = dist.log_prob(actions)\n",
    "    \n",
    "    # Calculate ratios\n",
    "    ratios = torch.exp(log_probs - old_log_probs)\n",
    "    \n",
    "    # Calculate surrogate losses\n",
    "    surrogate1 = ratios * advantages\n",
    "    surrogate2 = torch.clamp(ratios, 1 - clip_ratio, 1 + clip_ratio) * advantages\n",
    "    \n",
    "    actor_loss = -torch.min(surrogate1, surrogate2).mean() - 0.01 * dist.entropy().mean()  # Add entropy bonus for exploration\n",
    "    critic_loss = nn.MSELoss()(state_values.squeeze(), returns)\n",
    "    \n",
    "    loss = actor_loss + critic_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7b4642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.action_space[0].n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce57c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 3e-4\n",
    "input_dim = vec_envs.observation_space.shape[1]\n",
    "output_dim = int(vec_envs.action_space[0].n) # For discrete action spaces, it is one per keyboard in the discrete action space\n",
    "hidden_dim = 512\n",
    "num_episodes = 10_000\n",
    "max_frames = 30_000\n",
    "\n",
    "# Initialize actor-critic model and optimizer\n",
    "actor_critic = ActorCritic(input_dim, output_dim, hidden_dim)\n",
    "optimizer = Adam(actor_critic.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29daa644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48ab4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def plot_rewards(rewards: List[float], title: str = \"Training Rewards\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(rewards, label='Average Reward')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_env(env, actor_critic, num_episodes: int = 10, visualize: bool = True):\n",
    "    test_rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        truncated = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not (done or truncated):\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            action_probs, _ = actor_critic(state_tensor)\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample()\n",
    "            \n",
    "            next_state, reward, done, truncated, info = env.step(action.item())\n",
    "            episode_reward += reward\n",
    "            \n",
    "            if visualize:\n",
    "                frame = env.render()\n",
    "                plt.imshow(frame)\n",
    "                plt.axis('off')\n",
    "                plt.title(f'Test Episode - Reward: {reward:.2f}')\n",
    "                plt.show()\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        test_rewards.append(episode_reward)\n",
    "    avg_reward = np.mean(test_rewards)\n",
    "    print(f\"Average Test Reward over {num_episodes} episodes: {avg_reward:.2f}\")\n",
    "    return test_rewards\n",
    "\n",
    "def train_ppo(vec_envs, env, actor_critic, optimizer, num_episodes: int = 10000, max_frames: int = 30_000):\n",
    "    frame_idx = 0\n",
    "    test_rewards = []\n",
    "    episode_rewards = deque(maxlen=100)\n",
    "    \n",
    "    for episode in tqdm.tqdm(range(num_episodes)):\n",
    "        state, info = vec_envs.reset()\n",
    "        done = np.array([False] * vec_envs.num_envs)\n",
    "        truncated = np.array([False] * vec_envs.num_envs)\n",
    "        episode_reward = 0\n",
    "        states, actions, rewards, values, log_probs = [], [], [], [], []\n",
    "        \n",
    "        next_state = state  # Initialize next_state to current state\n",
    "\n",
    "        while (frame_idx < max_frames) and (not np.all(done)) and (not np.all(truncated)):\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            #state_tensor.shape\n",
    "            #torch.Size([1, 2, 8])\n",
    "            action_probs, value = actor_critic(state_tensor)\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample()\n",
    "            \n",
    "            next_state, reward, done, truncated, info = vec_envs.step(action.cpu().numpy()[0])\n",
    "            log_prob = dist.log_prob(action)\n",
    "            \n",
    "            states.append(state_tensor)\n",
    "            actions.append(action)\n",
    "            # convert reward to torch tensor\n",
    "            reward = torch.tensor(reward, dtype=torch.float32)\n",
    "            rewards.append(reward)\n",
    "            value = value.squeeze()\n",
    "            values.append(value)\n",
    "            log_probs.append(log_prob)\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            frame_idx += 1\n",
    "            \n",
    "        episode_rewards.append(episode_reward)\n",
    "        \n",
    "        # Only update if we have collected some data\n",
    "        if len(states) > 0:\n",
    "            # Compute GAE and returns\n",
    "            #torch.FloatTensor(next_state).unsqueeze(0).shape\n",
    "            #torch.Size([1, 2, 8])\n",
    "            _, next_value = actor_critic(torch.FloatTensor(next_state).unsqueeze(0))\n",
    "            next_value = next_value.squeeze()\n",
    "            returns = compute_gae(rewards, values, next_value)\n",
    "            \n",
    "            # Convert lists to tensors\n",
    "            states_tensor = torch.cat(states)\n",
    "            actions_tensor = torch.cat(actions)\n",
    "            log_probs_tensor = torch.cat(log_probs)\n",
    "            returns_tensor = torch.stack(returns)\n",
    "            \n",
    "            # Calculate advantages\n",
    "            values_tensor = torch.stack(values)\n",
    "            advantages = returns_tensor - values_tensor\n",
    "            \n",
    "            # Update the model using PPO\n",
    "            ppo_update(actor_critic, optimizer, states_tensor, actions_tensor, log_probs_tensor, returns_tensor, advantages)\n",
    "\n",
    "        if episode % 1000 == 0:\n",
    "            test_reward = test_env(env, actor_critic, num_episodes=10, visualize=False)\n",
    "            test_rewards.append(np.mean(test_reward))\n",
    "            avg_reward = np.mean(episode_rewards) if episode_rewards else 0\n",
    "            print(f\"Episode {episode}, Average Reward: {avg_reward:.2f}, Frame Index: {frame_idx}, Test Reward: {np.mean(test_reward):.2f}\")    \n",
    "    return test_rewards\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a53ad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0032],\n",
      "         [-0.0874],\n",
      "         [-0.0345],\n",
      "         [-0.0979]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/30000 [01:33<390:05:08, 46.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the PPO agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_rewards = \u001b[43mtrain_ppo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_critic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m plot_rewards(test_rewards, title=\u001b[33m\"\u001b[39m\u001b[33mPPO Training Rewards\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mtrain_ppo\u001b[39m\u001b[34m(vec_envs, env, actor_critic, optimizer, num_episodes, max_frames)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(next_value)\n\u001b[32m     84\u001b[39m next_value = next_value.squeeze()\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m returns = \u001b[43mcompute_gae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Convert lists to tensors\u001b[39;00m\n\u001b[32m     88\u001b[39m states_tensor = torch.cat(states)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcompute_gae\u001b[39m\u001b[34m(rewards, values, next_value, gamma, lam)\u001b[39m\n\u001b[32m      3\u001b[39m returns = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rewards))):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     delta = \u001b[43mrewards\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_value\u001b[49m - values[step]\n\u001b[32m      6\u001b[39m     gae = delta + gamma * lam * gae\n\u001b[32m      7\u001b[39m     returns.insert(\u001b[32m0\u001b[39m, gae + values[step])\n",
      "\u001b[31mTypeError\u001b[39m: Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations."
     ]
    }
   ],
   "source": [
    "# Train the PPO agent\n",
    "test_rewards = train_ppo(vec_envs, env, actor_critic, optimizer, num_episodes=30_000, max_frames=max_frames)\n",
    "plot_rewards(test_rewards, title=\"PPO Training Rewards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91e46c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: -126.10\n"
     ]
    }
   ],
   "source": [
    "# test the trained agent\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "frame = env.render()\n",
    "clear_output(wait=True)\n",
    "plt.imshow(frame)\n",
    "plt.axis('off')\n",
    "plt.title('Pendulum Environment')\n",
    "plt.show()\n",
    "done = False\n",
    "truncated = False\n",
    "total_reward = 0\n",
    "while not (done or truncated):\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action_probs, value = actor_critic(state)\n",
    "    dist = Categorical(action_probs)\n",
    "    action = dist.sample()\n",
    "    next_state, reward, done, truncated, info = env.step(action.cpu().numpy()[0])\n",
    "    state = next_state\n",
    "    frame = env.render()\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.title('Pendulum Environment')\n",
    "    plt.show()\n",
    "    total_reward += reward\n",
    "print(f\"Total Reward: {total_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State tensor shape: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "state, info = vec_envs.reset()\n",
    "episode_reward = 0\n",
    "states, actions, rewards, values, log_probs = [], [], [], [], []\n",
    "\n",
    "next_state = state  # Initialize next_state to current state\n",
    "state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "print(\"State tensor shape:\", state_tensor.shape)\n",
    "action_probs, value = actor_critic(state_tensor)def train_ppo(vec_envs, env, actor_critic, optimizer, num_episodes: int = 10000, max_frames: int = 30_000):\n",
    "    frame_idx = 0\n",
    "    test_rewards = []\n",
    "    episode_rewards = deque(maxlen=100)\n",
    "    \n",
    "    for episode in tqdm.tqdm(range(num_episodes)):\n",
    "        state, info = vec_envs.reset()\n",
    "        done = np.array([False, False])\n",
    "        truncated = np.array([False, False])\n",
    "        episode_reward = 0\n",
    "        states, actions, rewards, values, log_probs = [], [], [], [], []\n",
    "        \n",
    "        step_count = 0\n",
    "        max_steps_per_episode = 1000  # Prevent infinite episodes\n",
    "\n",
    "        while (frame_idx < max_frames) and (not np.all(done)) and (not np.all(truncated)) and (step_count < max_steps_per_episode):\n",
    "            # Don't add extra unsqueeze - state already has shape [2, 8]\n",
    "            state_tensor = torch.FloatTensor(state)\n",
    "            action_probs, value = actor_critic(state_tensor)\n",
    "            \n",
    "            # Create distribution for each environment\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample()\n",
    "            \n",
    "            # Use actions for both environments\n",
    "            next_state, reward, done, truncated, info = vec_envs.step(action.cpu().numpy())\n",
    "            log_prob = dist.log_prob(action)\n",
    "            \n",
    "            states.append(state_tensor)\n",
    "            actions.append(action)\n",
    "            \n",
    "            # Convert reward to torch tensor and sum across environments\n",
    "            reward_tensor = torch.tensor(reward, dtype=torch.float32)\n",
    "            rewards.append(reward_tensor.sum())  # Sum rewards across environments\n",
    "            \n",
    "            # Sum values and log_probs across environments\n",
    "            values.append(value.sum())\n",
    "            log_probs.append(log_prob.sum())\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward_tensor.sum()\n",
    "            frame_idx += 1\n",
    "            step_count += 1\n",
    "            \n",
    "        episode_rewards.append(episode_reward.item() if isinstance(episode_reward, torch.Tensor) else episode_reward)\n",
    "        \n",
    "        # Only update if we have collected some data\n",
    "        if len(states) > 0:\n",
    "            # Compute GAE and returns\n",
    "            state_tensor = torch.FloatTensor(next_state)\n",
    "            _, next_value = actor_critic(state_tensor)\n",
    "            next_value = next_value.sum()  # Sum across environments\n",
    "            \n",
    "            returns = compute_gae(rewards, values, next_value)\n",
    "            \n",
    "            # Convert lists to tensors\n",
    "            states_tensor = torch.stack(states)\n",
    "            actions_tensor = torch.stack(actions)\n",
    "            log_probs_tensor = torch.stack(log_probs)\n",
    "            returns_tensor = torch.stack(returns)\n",
    "            \n",
    "            # Calculate advantages\n",
    "            values_tensor = torch.stack(values)\n",
    "            advantages = returns_tensor - values_tensor\n",
    "            \n",
    "            # Normalize advantages for better training stability\n",
    "            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "            \n",
    "            # Update the model using PPO\n",
    "            ppo_update(actor_critic, optimizer, states_tensor, actions_tensor, log_probs_tensor, returns_tensor, advantages)\n",
    "\n",
    "        if episode % 100 == 0:  # Test more frequently\n",
    "            test_reward = test_env(env, actor_critic, num_episodes=5, visualize=False)\n",
    "            test_rewards.append(np.mean(test_reward))\n",
    "            avg_reward = np.mean(episode_rewards) if episode_rewards else 0\n",
    "            print(f\"Episode {episode}, Average Reward: {avg_reward:.2f}, Frame Index: {frame_idx}, Test Reward: {np.mean(test_reward):.2f}\")    \n",
    "    return test_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1968af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1961, 0.3169, 0.2212, 0.2657],\n",
       "         [0.1790, 0.3054, 0.2469, 0.2687],\n",
       "         [0.1613, 0.3620, 0.2369, 0.2398],\n",
       "         [0.1775, 0.3610, 0.2214, 0.2402]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "216f9425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Categorical(probs: torch.Size([1, 4, 4])), tensor([[1, 2, 2, 2]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Categorical(action_probs)\n",
    "action = dist.sample()\n",
    "dist, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e648948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "705feaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ed99598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1760db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "325daf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0207015 ,  1.4376045 , -0.70805174,  0.36898848,  0.02823097,\n",
       "          0.22109969,  0.        ,  0.        ],\n",
       "        [ 0.0130722 ,  1.4391944 ,  0.4405354 ,  0.44750464, -0.01374587,\n",
       "         -0.09139954,  0.        ,  0.        ],\n",
       "        [ 0.01492996,  1.378388  ,  0.5005176 , -0.48031557, -0.02251425,\n",
       "         -0.17477141,  0.        ,  0.        ],\n",
       "        [-0.01559029,  1.4337385 , -0.7815169 ,  0.52460545,  0.01885197,\n",
       "          0.19445577,  0.        ,  0.        ]], dtype=float32),\n",
       " array([-1.49397397, -3.43256539,  1.92220309, -3.01464674]),\n",
       " array([False, False, False, False]),\n",
       " array([False, False, False, False]),\n",
       " {})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_envs.step(action.cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35605f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirtyRL (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
